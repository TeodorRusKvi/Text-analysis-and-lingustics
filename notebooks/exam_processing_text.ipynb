{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Political Lean</th>\n",
       "      <th>Score</th>\n",
       "      <th>Id</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>URL</th>\n",
       "      <th>Num of Comments</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date Created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No matter who someone is, how they look like, ...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>1</td>\n",
       "      <td>t5fybt</td>\n",
       "      <td>socialism</td>\n",
       "      <td>https://v.redd.it/ng5fyl7hp2l81</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.646272e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden speech draws 38.2 million U.S. TV viewers</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>6</td>\n",
       "      <td>t5fqdn</td>\n",
       "      <td>democrats</td>\n",
       "      <td>https://www.reuters.com/world/us/biden-speech-...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.646271e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State of the union</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>1</td>\n",
       "      <td>t5fj9a</td>\n",
       "      <td>DemocraticSocialism</td>\n",
       "      <td>https://www.reddit.com/r/DemocraticSocialism/c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Who watched the state of the union last night ...</td>\n",
       "      <td>1.646270e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Should Just Give Poor People Money</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>7</td>\n",
       "      <td>t5f7n9</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>https://youtu.be/a80kRjpubG0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.646270e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do it for the Dew</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>6</td>\n",
       "      <td>t5es2c</td>\n",
       "      <td>democrats</td>\n",
       "      <td>https://i.redd.it/drmunn90f2l81.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.646268e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Political Lean  Score  \\\n",
       "0  No matter who someone is, how they look like, ...        Liberal      1   \n",
       "1    Biden speech draws 38.2 million U.S. TV viewers        Liberal      6   \n",
       "2                                 State of the union        Liberal      1   \n",
       "3              We Should Just Give Poor People Money        Liberal      7   \n",
       "4                                  Do it for the Dew        Liberal      6   \n",
       "\n",
       "       Id            Subreddit  \\\n",
       "0  t5fybt            socialism   \n",
       "1  t5fqdn            democrats   \n",
       "2  t5fj9a  DemocraticSocialism   \n",
       "3  t5f7n9      SocialDemocracy   \n",
       "4  t5es2c            democrats   \n",
       "\n",
       "                                                 URL  Num of Comments  \\\n",
       "0                    https://v.redd.it/ng5fyl7hp2l81                0   \n",
       "1  https://www.reuters.com/world/us/biden-speech-...                1   \n",
       "2  https://www.reddit.com/r/DemocraticSocialism/c...                1   \n",
       "3                       https://youtu.be/a80kRjpubG0                3   \n",
       "4                https://i.redd.it/drmunn90f2l81.jpg                1   \n",
       "\n",
       "                                                Text  Date Created  \n",
       "0                                                NaN  1.646272e+09  \n",
       "1                                                NaN  1.646271e+09  \n",
       "2  Who watched the state of the union last night ...  1.646270e+09  \n",
       "3                                                NaN  1.646270e+09  \n",
       "4                                                NaN  1.646268e+09  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset to see its structure\n",
    "url_data = 'https://raw.githubusercontent.com/TeodorRusKvi/Tekstanalyse/main/git_NLP_data/'\n",
    "\n",
    "df = pd.read_csv(url_data+ 'file_name.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Subreddits: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Subreddit\n",
       "conservatives          1000\n",
       "SocialDemocracy         997\n",
       "alltheleft              997\n",
       "socialism               975\n",
       "Libertarian             975\n",
       "Capitalism              975\n",
       "progressive             974\n",
       "republicans             948\n",
       "democrats               941\n",
       "feminisms               935\n",
       "DemocraticSocialism     922\n",
       "Liberal                 904\n",
       "anarchocapitalism       637\n",
       "Communist               574\n",
       "RadicalFeminism         100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze the 'Subreddit' column\n",
    "subreddit_counts = df['Subreddit'].value_counts()\n",
    "\n",
    "# Number of unique subreddits\n",
    "unique_subreddits = len(subreddit_counts)\n",
    "\n",
    "# Display the number of unique subreddits and the first few rows of the distribution\n",
    "print(f'Unique Subreddits: {unique_subreddits}')\n",
    "subreddit_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Political Lean\n",
       "Liberal         8319\n",
       "Conservative    4535\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political_lean_counts = df['Political Lean'].value_counts()\n",
    "political_lean_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the text and title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Text' column to string type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "# Concatenate the 'Title' and 'Text' columns\n",
    "#This is because we want as much text as possible\n",
    "df['All_text'] = df['Title'] + ' ' + df['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for empty text rows in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12854"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_check = ['All_text']  # Sett inn de relevante kolonnenavnene\n",
    "empty_rows = df[cols_to_check].isna().all(axis=1)\n",
    "len(empty_rows==False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 12854/12854 [04:40<00:00, 45.77it/s]\n"
     ]
    }
   ],
   "source": [
    "tq.pandas(desc='Processing')\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a list of stopwords (this is just an example, ensure to load or define a comprehensive list)\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Function to tokenize and lemmatize a single text, while removing stopwords and keeping certain abbreviations\n",
    "def tokenize_and_lemmatize_text(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    lemmatized_tokens = []\n",
    "    for token in (doc):\n",
    "        # Check if the token matches specific abbreviations or consists of alphabetic characters\n",
    "        if token.text in ['U.S.', 'U.S.A.'] or (token.is_alpha and token.lemma_.lower() not in stop_words):\n",
    "            # Directly add the abbreviations or lemmatize and lower-case other tokens\n",
    "            token_to_add = token.text if token.text in ['U.S.', 'U.S.A.'] else token.lemma_.lower()\n",
    "            lemmatized_tokens.append(token_to_add)\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "\n",
    "# Apply the tokenization and lemmatization function to each row in the column\n",
    "df['Processed'] = df['All_text'].progress_apply(tokenize_and_lemmatize_text)\n",
    "#Fixing US and USA to words instead of abbreviation\n",
    "df['Processed'] = df['Processed'].replace(['U.S.', 'U.S.A.'], ['US', 'USA'], regex=True)\n",
    "df['All_text'] = df['All_text'].replace(['U.S.', 'U.S.A.'], ['US', 'USA'], regex=True)\n",
    "df['Processed'] = df['Processed'].astype(str)\n",
    "df['All_text'] = df['All_text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating columns with the POS tags and Dependency tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(text):\n",
    "    doc = nlp(text)\n",
    "    dependency_tags = [token.dep_ for token in doc]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    \n",
    "    # Extract named entities, ensure to join multiple-word entities, and represent them with their labels\n",
    "    named_entities = [f\"{ent.text} ({ent.label_})\" for ent in doc.ents]\n",
    "    \n",
    "    return dependency_tags, pos_tags, named_entities\n",
    "\n",
    "# Apply the function to the 'Processed' column and create new columns for each feature\n",
    "df['Dependency_Tags'], df['POS_Tags'], df['Named_Entities'] = zip(*df['Processed'].apply(extract_text_features))\n",
    "\n",
    "# Show the first few rows to verify the new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at the new dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataset for further analyzis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Political Lean': 'Political_Lean'}, inplace=True)\n",
    "# Create a new dataframe with only the 'All_text', 'Political Lean', and 'Subreddit' columns\n",
    "new_df = df[['All_text', 'Processed', 'Political_Lean', 'Subreddit', 'Dependency_Tags', 'POS_Tags', ]].copy()\n",
    "X_text = new_df['Processed']\n",
    "#Saving the dataframe\n",
    "new_df.to_csv('new_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_text</th>\n",
       "      <th>Processed</th>\n",
       "      <th>Political_Lean</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Dependency_Tags</th>\n",
       "      <th>POS_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No matter who someone is, how they look like, ...</td>\n",
       "      <td>matter look like language speak wear remember ...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>socialism</td>\n",
       "      <td>[advmod, ROOT, prep, compound, compound, pobj,...</td>\n",
       "      <td>[ADV, VERB, ADP, NOUN, NOUN, NOUN, VERB, ADJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden speech draws 38.2 million US TV viewers nan</td>\n",
       "      <td>biden speech draw million US tv viewer nan</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>[compound, nsubj, ROOT, nummod, compound, comp...</td>\n",
       "      <td>[PROPN, NOUN, VERB, NUM, PROPN, PROPN, NOUN, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State of the union Who watched the state of th...</td>\n",
       "      <td>state union watch state union night opinion</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>DemocraticSocialism</td>\n",
       "      <td>[compound, nsubj, ROOT, compound, compound, co...</td>\n",
       "      <td>[NOUN, PROPN, VERB, NOUN, PROPN, NOUN, NOUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Should Just Give Poor People Money nan</td>\n",
       "      <td>poor people money nan</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>[amod, nsubj, compound, ROOT]</td>\n",
       "      <td>[ADJ, NOUN, PROPN, PROPN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do it for the Dew nan</td>\n",
       "      <td>dew nan</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>[compound, ROOT]</td>\n",
       "      <td>[PROPN, PROPN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            All_text  \\\n",
       "0  No matter who someone is, how they look like, ...   \n",
       "1  Biden speech draws 38.2 million US TV viewers nan   \n",
       "2  State of the union Who watched the state of th...   \n",
       "3          We Should Just Give Poor People Money nan   \n",
       "4                              Do it for the Dew nan   \n",
       "\n",
       "                                           Processed Political_Lean  \\\n",
       "0  matter look like language speak wear remember ...        Liberal   \n",
       "1         biden speech draw million US tv viewer nan        Liberal   \n",
       "2        state union watch state union night opinion        Liberal   \n",
       "3                              poor people money nan        Liberal   \n",
       "4                                            dew nan        Liberal   \n",
       "\n",
       "             Subreddit                                    Dependency_Tags  \\\n",
       "0            socialism  [advmod, ROOT, prep, compound, compound, pobj,...   \n",
       "1            democrats  [compound, nsubj, ROOT, nummod, compound, comp...   \n",
       "2  DemocraticSocialism  [compound, nsubj, ROOT, compound, compound, co...   \n",
       "3      SocialDemocracy                      [amod, nsubj, compound, ROOT]   \n",
       "4            democrats                                   [compound, ROOT]   \n",
       "\n",
       "                                            POS_Tags  \n",
       "0  [ADV, VERB, ADP, NOUN, NOUN, NOUN, VERB, ADJ, ...  \n",
       "1  [PROPN, NOUN, VERB, NUM, PROPN, PROPN, NOUN, P...  \n",
       "2       [NOUN, PROPN, VERB, NOUN, PROPN, NOUN, NOUN]  \n",
       "3                          [ADJ, NOUN, PROPN, PROPN]  \n",
       "4                                     [PROPN, PROPN]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
