{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Importing libraries"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:23:24.015749Z","iopub.status.busy":"2024-04-19T16:23:24.015249Z","iopub.status.idle":"2024-04-19T16:23:24.027658Z","shell.execute_reply":"2024-04-19T16:23:24.026466Z","shell.execute_reply.started":"2024-04-19T16:23:24.015717Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","from transformers import Trainer, TrainingArguments\n","from transformers import TrainingArguments, Trainer\n","from transformers import DataCollatorWithPadding"]},{"cell_type":"markdown","metadata":{},"source":["## Loading the data"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:41.601209Z","iopub.status.busy":"2024-04-19T16:08:41.600645Z","iopub.status.idle":"2024-04-19T16:08:42.265357Z","shell.execute_reply":"2024-04-19T16:08:42.264308Z","shell.execute_reply.started":"2024-04-19T16:08:41.601183Z"},"trusted":true},"outputs":[],"source":["url_data = 'https://raw.githubusercontent.com/TeodorRusKvi/Tekstanalyse/main/git_NLP_data/'\n","\n","df = pd.read_csv(url_data + 'new_df.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:42.271645Z","iopub.status.busy":"2024-04-19T16:08:42.271005Z","iopub.status.idle":"2024-04-19T16:08:43.290540Z","shell.execute_reply":"2024-04-19T16:08:43.289531Z","shell.execute_reply.started":"2024-04-19T16:08:42.271610Z"},"trusted":true},"outputs":[],"source":["y_liberal = pd.read_csv(url_data + 'y_liberal.csv')\n","y_data = pd.read_csv(url_data + 'y_data.csv')\n","X_text = pd.read_csv(url_data + 'X_text.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:43.292092Z","iopub.status.busy":"2024-04-19T16:08:43.291800Z","iopub.status.idle":"2024-04-19T16:08:43.298979Z","shell.execute_reply":"2024-04-19T16:08:43.297998Z","shell.execute_reply.started":"2024-04-19T16:08:43.292069Z"},"trusted":true},"outputs":[],"source":["X_text= X_text['Processed'].tolist()\n","y = y_liberal"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:43.300168Z","iopub.status.busy":"2024-04-19T16:08:43.299918Z","iopub.status.idle":"2024-04-19T16:08:43.320362Z","shell.execute_reply":"2024-04-19T16:08:43.319638Z","shell.execute_reply.started":"2024-04-19T16:08:43.300148Z"},"trusted":true},"outputs":[],"source":["# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.3, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["### Creating a class for creating datasets for the model"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:43.321662Z","iopub.status.busy":"2024-04-19T16:08:43.321385Z","iopub.status.idle":"2024-04-19T16:08:43.328768Z","shell.execute_reply":"2024-04-19T16:08:43.327804Z","shell.execute_reply.started":"2024-04-19T16:08:43.321640Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","import torch\n","\n","class TextDataset(Dataset):\n","    def __init__(self, text, labels, tokenizer, max_length):\n","        self.tokenized_txt = tokenizer(\n","            text,\n","            max_length=max_length,\n","            truncation=True,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\"\n","        )\n","        self.labels = torch.tensor(labels)\n","      \n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {\n","            key: self.tokenized_txt[key][idx] for key in self.tokenized_txt\n","        }\n","        item['labels'] = self.labels[idx]\n","        return item"]},{"cell_type":"markdown","metadata":{},"source":["## The Distilbert model form Hugging Face"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:43.330103Z","iopub.status.busy":"2024-04-19T16:08:43.329873Z","iopub.status.idle":"2024-04-19T16:08:46.043251Z","shell.execute_reply":"2024-04-19T16:08:46.042203Z","shell.execute_reply.started":"2024-04-19T16:08:43.330083Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38dfca4a077845beb5ad0a5c6deed1b0","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22c865ce7b5545e899c9c459835f892a","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"743fb470b53e42a888fcd0f7e031a106","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6867bbf172849a892725422cebe9371","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["Distilbert = 'distilbert-base-uncased-finetuned-sst-2-english'\n","Roberta = 'roberta-base'\n","Bert = 'bert-base-uncased'\n","\n","#Initializing the model and the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(Distilbert)\n","model = AutoModelForSequenceClassification.from_pretrained(Distilbert, num_labels=2)"]},{"cell_type":"markdown","metadata":{},"source":["### Creating datasets"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:47.258451Z","iopub.status.busy":"2024-04-19T16:08:47.258147Z","iopub.status.idle":"2024-04-19T16:08:47.267840Z","shell.execute_reply":"2024-04-19T16:08:47.266863Z","shell.execute_reply.started":"2024-04-19T16:08:47.258425Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([  101,  2329, 15178,  4674,  2954,  3789,   102,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'labels': tensor([1])}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset_train = TextDataset(\n","    X_train, \n","    y_train.values, \n","    tokenizer, \n","    max_length=20\n",")\n","\n","dataset_val = TextDataset(\n","    X_val, \n","    y_val.values, \n","    tokenizer, \n","    max_length=20\n",")\n","\n","dataset_test = TextDataset(\n","    X_test, \n","    y_test.values, \n","    tokenizer, \n","    max_length=20\n",")\n","\n","# An example of the test dataset for the distilbert moodel\n","dataset_test[9]"]},{"cell_type":"markdown","metadata":{},"source":["## Training Setup"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:47.276872Z","iopub.status.busy":"2024-04-19T16:08:47.276103Z","iopub.status.idle":"2024-04-19T16:08:47.286366Z","shell.execute_reply":"2024-04-19T16:08:47.285507Z","shell.execute_reply.started":"2024-04-19T16:08:47.276839Z"},"trusted":true},"outputs":[],"source":["# create a dir to store model checkpoints\n","my_dir = 'roberta_checkpoints'"]},{"cell_type":"markdown","metadata":{},"source":["### Setting up the parameters for the Hugging Face Trainer"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T17:20:23.097287Z","iopub.status.busy":"2024-04-19T17:20:23.096823Z","iopub.status.idle":"2024-04-19T17:20:23.110523Z","shell.execute_reply":"2024-04-19T17:20:23.109423Z","shell.execute_reply.started":"2024-04-19T17:20:23.097256Z"},"trusted":true},"outputs":[],"source":["# Creating a data collator\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","# define training arguments\n","training_args = TrainingArguments(\n","    output_dir=my_dir,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    evaluation_strategy=\"epoch\",\n","    num_train_epochs=20,\n","    weight_decay=0.01,\n","    save_strategy='epoch',\n","    load_best_model_at_end=True,\n","    learning_rate=0.00002,\n","    lr_scheduler_type='cosine',\n","    metric_for_best_model='accuracy'\n","    \n",")"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T17:20:26.654838Z","iopub.status.busy":"2024-04-19T17:20:26.654227Z","iopub.status.idle":"2024-04-19T17:20:26.661655Z","shell.execute_reply":"2024-04-19T17:20:26.660545Z","shell.execute_reply.started":"2024-04-19T17:20:26.654809Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T17:20:28.380429Z","iopub.status.busy":"2024-04-19T17:20:28.379674Z","iopub.status.idle":"2024-04-19T17:20:28.396606Z","shell.execute_reply":"2024-04-19T17:20:28.395408Z","shell.execute_reply.started":"2024-04-19T17:20:28.380395Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Training the model"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T17:20:31.043018Z","iopub.status.busy":"2024-04-19T17:20:31.042641Z","iopub.status.idle":"2024-04-19T17:26:05.278247Z","shell.execute_reply":"2024-04-19T17:26:05.277282Z","shell.execute_reply.started":"2024-04-19T17:20:31.042991Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5640' max='5640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5640/5640 05:33, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.860493</td>\n","      <td>0.744295</td>\n","      <td>0.801450</td>\n","      <td>0.806321</td>\n","      <td>0.796637</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.128300</td>\n","      <td>1.090024</td>\n","      <td>0.746888</td>\n","      <td>0.802589</td>\n","      <td>0.811120</td>\n","      <td>0.794235</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.128300</td>\n","      <td>1.166000</td>\n","      <td>0.750519</td>\n","      <td>0.808595</td>\n","      <td>0.803797</td>\n","      <td>0.813451</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.087300</td>\n","      <td>1.326371</td>\n","      <td>0.748444</td>\n","      <td>0.804040</td>\n","      <td>0.811582</td>\n","      <td>0.796637</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.087300</td>\n","      <td>1.403468</td>\n","      <td>0.757261</td>\n","      <td>0.820414</td>\n","      <td>0.787767</td>\n","      <td>0.855885</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.060600</td>\n","      <td>1.449873</td>\n","      <td>0.751037</td>\n","      <td>0.811912</td>\n","      <td>0.795088</td>\n","      <td>0.829464</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.060600</td>\n","      <td>1.665433</td>\n","      <td>0.725622</td>\n","      <td>0.768693</td>\n","      <td>0.846821</td>\n","      <td>0.703763</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.047000</td>\n","      <td>1.445720</td>\n","      <td>0.753631</td>\n","      <td>0.809467</td>\n","      <td>0.811093</td>\n","      <td>0.807846</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.036500</td>\n","      <td>1.568065</td>\n","      <td>0.756224</td>\n","      <td>0.812450</td>\n","      <td>0.809865</td>\n","      <td>0.815052</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.036500</td>\n","      <td>1.650692</td>\n","      <td>0.759855</td>\n","      <td>0.814874</td>\n","      <td>0.813898</td>\n","      <td>0.815853</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.023400</td>\n","      <td>1.651710</td>\n","      <td>0.763485</td>\n","      <td>0.820047</td>\n","      <td>0.808560</td>\n","      <td>0.831865</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.023400</td>\n","      <td>1.622317</td>\n","      <td>0.752075</td>\n","      <td>0.807103</td>\n","      <td>0.813670</td>\n","      <td>0.800641</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.017800</td>\n","      <td>1.678341</td>\n","      <td>0.762448</td>\n","      <td>0.821512</td>\n","      <td>0.800304</td>\n","      <td>0.843875</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.017800</td>\n","      <td>1.740229</td>\n","      <td>0.764523</td>\n","      <td>0.819268</td>\n","      <td>0.814727</td>\n","      <td>0.823859</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.015500</td>\n","      <td>1.771850</td>\n","      <td>0.760373</td>\n","      <td>0.817536</td>\n","      <td>0.806703</td>\n","      <td>0.828663</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.011000</td>\n","      <td>1.784046</td>\n","      <td>0.763485</td>\n","      <td>0.819334</td>\n","      <td>0.810980</td>\n","      <td>0.827862</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.011000</td>\n","      <td>1.813841</td>\n","      <td>0.763485</td>\n","      <td>0.818327</td>\n","      <td>0.814433</td>\n","      <td>0.822258</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.010600</td>\n","      <td>1.819239</td>\n","      <td>0.763485</td>\n","      <td>0.821036</td>\n","      <td>0.805235</td>\n","      <td>0.837470</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.010600</td>\n","      <td>1.832527</td>\n","      <td>0.766079</td>\n","      <td>0.821669</td>\n","      <td>0.811719</td>\n","      <td>0.831865</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.011200</td>\n","      <td>1.835305</td>\n","      <td>0.765041</td>\n","      <td>0.820309</td>\n","      <td>0.812893</td>\n","      <td>0.827862</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=5640, training_loss=0.04007929650181574, metrics={'train_runtime': 333.8215, 'train_samples_per_second': 539.031, 'train_steps_per_second': 16.895, 'total_flos': 931100926334400.0, 'train_loss': 0.04007929650181574, 'epoch': 20.0})"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["# train the model\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation of the model"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T17:27:18.601931Z","iopub.status.busy":"2024-04-19T17:27:18.601179Z","iopub.status.idle":"2024-04-19T17:27:19.537116Z","shell.execute_reply":"2024-04-19T17:27:19.535983Z","shell.execute_reply.started":"2024-04-19T17:27:18.601897Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [61/61 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.824212908744812, 'eval_accuracy': 0.7651632970451011, 'eval_f1': 0.8232539992196645, 'eval_precision': 0.8121632024634334, 'eval_recall': 0.8346518987341772, 'eval_runtime': 0.9265, 'eval_samples_per_second': 2082.118, 'eval_steps_per_second': 65.842, 'epoch': 20.0}\n"]}],"source":["test_result = trainer.evaluate(dataset_test)\n","print(test_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:08:47.310506Z","iopub.status.idle":"2024-04-19T16:08:47.310825Z","shell.execute_reply":"2024-04-19T16:08:47.310684Z","shell.execute_reply.started":"2024-04-19T16:08:47.310671Z"},"trusted":true},"outputs":[],"source":["# Save the model to a specified directory\n","Dir = 'models/Bert/'\n","model_directory = Dir + \"model\"\n","trainer.save_model(model_directory)\n","\n","# If you also want to save the tokenizer used during training:\n","tokenizer_directory = Dir + 'tokenizer_dir'\n","trainer.tokenizer.save_pretrained(tokenizer_directory)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
