{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tq\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Political Lean</th>\n",
       "      <th>Score</th>\n",
       "      <th>Id</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>URL</th>\n",
       "      <th>Num of Comments</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date Created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No matter who someone is, how they look like, ...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>1</td>\n",
       "      <td>t5fybt</td>\n",
       "      <td>socialism</td>\n",
       "      <td>https://v.redd.it/ng5fyl7hp2l81</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.646272e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden speech draws 38.2 million U.S. TV viewers</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>6</td>\n",
       "      <td>t5fqdn</td>\n",
       "      <td>democrats</td>\n",
       "      <td>https://www.reuters.com/world/us/biden-speech-...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.646271e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State of the union</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>1</td>\n",
       "      <td>t5fj9a</td>\n",
       "      <td>DemocraticSocialism</td>\n",
       "      <td>https://www.reddit.com/r/DemocraticSocialism/c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Who watched the state of the union last night ...</td>\n",
       "      <td>1.646270e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Should Just Give Poor People Money</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>7</td>\n",
       "      <td>t5f7n9</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>https://youtu.be/a80kRjpubG0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.646270e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do it for the Dew</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>6</td>\n",
       "      <td>t5es2c</td>\n",
       "      <td>democrats</td>\n",
       "      <td>https://i.redd.it/drmunn90f2l81.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.646268e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Political Lean  Score  \\\n",
       "0  No matter who someone is, how they look like, ...        Liberal      1   \n",
       "1    Biden speech draws 38.2 million U.S. TV viewers        Liberal      6   \n",
       "2                                 State of the union        Liberal      1   \n",
       "3              We Should Just Give Poor People Money        Liberal      7   \n",
       "4                                  Do it for the Dew        Liberal      6   \n",
       "\n",
       "       Id            Subreddit  \\\n",
       "0  t5fybt            socialism   \n",
       "1  t5fqdn            democrats   \n",
       "2  t5fj9a  DemocraticSocialism   \n",
       "3  t5f7n9      SocialDemocracy   \n",
       "4  t5es2c            democrats   \n",
       "\n",
       "                                                 URL  Num of Comments  \\\n",
       "0                    https://v.redd.it/ng5fyl7hp2l81                0   \n",
       "1  https://www.reuters.com/world/us/biden-speech-...                1   \n",
       "2  https://www.reddit.com/r/DemocraticSocialism/c...                1   \n",
       "3                       https://youtu.be/a80kRjpubG0                3   \n",
       "4                https://i.redd.it/drmunn90f2l81.jpg                1   \n",
       "\n",
       "                                                Text  Date Created  \n",
       "0                                                NaN  1.646272e+09  \n",
       "1                                                NaN  1.646271e+09  \n",
       "2  Who watched the state of the union last night ...  1.646270e+09  \n",
       "3                                                NaN  1.646270e+09  \n",
       "4                                                NaN  1.646268e+09  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset to see its structure\n",
    "url_data = 'https://raw.githubusercontent.com/TeodorRusKvi/Tekstanalyse/main/git_NLP_data/'\n",
    "\n",
    "df = pd.read_csv(url_data+ 'file_name.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Subreddits: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Subreddit\n",
       "conservatives          1000\n",
       "SocialDemocracy         997\n",
       "alltheleft              997\n",
       "socialism               975\n",
       "Libertarian             975\n",
       "Capitalism              975\n",
       "progressive             974\n",
       "republicans             948\n",
       "democrats               941\n",
       "feminisms               935\n",
       "DemocraticSocialism     922\n",
       "Liberal                 904\n",
       "anarchocapitalism       637\n",
       "Communist               574\n",
       "RadicalFeminism         100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze the 'Subreddit' column\n",
    "subreddit_counts = df['Subreddit'].value_counts()\n",
    "\n",
    "# Number of unique subreddits\n",
    "unique_subreddits = len(subreddit_counts)\n",
    "\n",
    "# Display the number of unique subreddits and the first few rows of the distribution\n",
    "print(f'Unique Subreddits: {unique_subreddits}')\n",
    "subreddit_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Political Lean\n",
       "Liberal         8319\n",
       "Conservative    4535\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political_lean_counts = df['Political Lean'].value_counts()\n",
    "political_lean_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the text and title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Text' column to string type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "#Fixing US and USA to words instead of abbreviation\n",
    "\n",
    "\n",
    "# Concatenate the 'Title' and 'Text' columns\n",
    "#This is because we want as much text as possible\n",
    "df['All_text'] = df['Title'] + ' ' + df['Text']\n",
    "df['All_text'] = df['All_text'].replace(['U.S.', 'U.S.A.'], ['US', 'USA'], regex=True)\n",
    "df['All_text'] = df['All_text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for empty text rows in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12854"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_check = ['All_text']  # Sett inn de relevante kolonnenavnene\n",
    "empty_rows = df[cols_to_check].isna().all(axis=1)\n",
    "len(empty_rows==False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_rules = {\n",
    "    re.compile(r\"\\b(u\\.s\\.a\\.|u\\.s\\.a)\\b\", re.IGNORECASE): \"USA\",\n",
    "    re.compile(r\"\\b(u\\.s\\.|us)\\b\", re.IGNORECASE): \"USA\"\n",
    "}\n",
    "\n",
    "def apply_regex_rules(text):\n",
    "    \"\"\"Apply regex rules to text for abbreviation handling.\"\"\"\n",
    "    for pattern, replacement in regex_rules.items():\n",
    "        text = pattern.sub(replacement, text)\n",
    "    return text\n",
    "\n",
    "# Usage with pandas apply\n",
    "df['All_text'] = df['All_text'].apply(apply_regex_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 12854/12854 [02:33<00:00, 83.77it/s] \n",
      "Processing: 100%|██████████| 12854/12854 [02:05<00:00, 102.24it/s]\n"
     ]
    }
   ],
   "source": [
    "tq.pandas(desc='Processing')\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a list of stopwords (this is just an example, ensure to load or define a comprehensive list)\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Function to tokenize and lemmatize a single text, while removing stopwords and keeping certain abbreviations\n",
    "def tokenize_without_stopwords(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    lemmatized_tokens = []\n",
    "    for token in (doc):\n",
    "        # Check if the token matches specific abbreviations or consists of alphabetic characters\n",
    "        if token.is_alpha and token.lemma_.lower() not in stop_words:\n",
    "            # Directly add the abbreviations or lemmatize and lower-case other tokens\n",
    "            token_to_add = token.lemma_.lower()\n",
    "            lemmatized_tokens.append(token_to_add)\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "\n",
    "# Function to tokenize and lemmatize a single text, including stopwords\n",
    "def tokenize_with_stopwords(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    lemmatized_tokens = []\n",
    "    for token in (doc):\n",
    "        if token.is_alpha:\n",
    "            token_to_add = token.lemma_.lower()\n",
    "            lemmatized_tokens.append(token_to_add)\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "\n",
    "# Apply the tokenization and lemmatization function to each row in the column\n",
    "df['without_stopwords'] = df['All_text'].progress_apply(tokenize_without_stopwords)\n",
    "df['with_stopwords'] = df['All_text'].progress_apply(tokenize_with_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating columns with the POS tags and Dependency tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(text):\n",
    "    doc = nlp(text)\n",
    "    dependency_tags = [token.dep_ for token in doc]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    \n",
    "    # Extract named entities, ensure to join multiple-word entities, and represent them with their labels\n",
    "    named_entities = [f\"{ent.text} ({ent.label_})\" for ent in doc.ents]\n",
    "    \n",
    "    return dependency_tags, pos_tags, named_entities\n",
    "\n",
    "# Apply the function to the 'Processed' column and create new columns for each feature\n",
    "df['Dependency_Tags'], df['POS_Tags'], df['Named_Entities'] = zip(*df['with_stopwords'].apply(extract_text_features))\n",
    "\n",
    "# Show the first few rows to verify the new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at the new dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataset for further analyzis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Political Lean': 'Political_Lean'}, inplace=True)\n",
    "# Create a new dataframe with only the 'All_text', 'Political Lean', and 'Subreddit' columns\n",
    "new_df = df[['All_text', 'with_stopwords', 'without_stopwords', 'Political_Lean', 'Subreddit', 'Dependency_Tags', 'POS_Tags', ]].copy()\n",
    "#Saving the dataframe\n",
    "new_df.to_csv('new_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_text</th>\n",
       "      <th>with_stopwords</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>Political_Lean</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Dependency_Tags</th>\n",
       "      <th>POS_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No matter who someone is, how they look like, ...</td>\n",
       "      <td>no matter who someone be how they look like wh...</td>\n",
       "      <td>matter look like language speak wear remember ...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>socialism</td>\n",
       "      <td>[neg, advmod, attr, nsubj, ccomp, advmod, nsub...</td>\n",
       "      <td>[ADV, ADV, PRON, PRON, VERB, SCONJ, PRON, VERB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden speech draws 38.2 million USA TV viewers...</td>\n",
       "      <td>biden speech draw million usa tv viewer nan</td>\n",
       "      <td>biden speech draw million usa tv viewer nan</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>[compound, nsubj, ROOT, nummod, compound, comp...</td>\n",
       "      <td>[PROPN, NOUN, VERB, NUM, PROPN, PROPN, PROPN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State of the union Who watched the state of th...</td>\n",
       "      <td>state of the union who watch the state of the ...</td>\n",
       "      <td>state union watch state union night opinion</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>DemocraticSocialism</td>\n",
       "      <td>[ROOT, prep, det, pobj, nsubj, relcl, det, dob...</td>\n",
       "      <td>[NOUN, ADP, DET, NOUN, PRON, VERB, DET, NOUN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Should Just Give Poor People Money nan</td>\n",
       "      <td>we should just give poor people money nan</td>\n",
       "      <td>poor people money nan</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>[nsubj, aux, advmod, ROOT, amod, dative, dobj,...</td>\n",
       "      <td>[PRON, AUX, ADV, VERB, ADJ, NOUN, PROPN, PROPN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do it for the Dew nan</td>\n",
       "      <td>do it for the dew nan</td>\n",
       "      <td>dew nan</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>[ROOT, dobj, prep, det, pobj, npadvmod]</td>\n",
       "      <td>[VERB, PRON, ADP, DET, PROPN, PROPN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            All_text  \\\n",
       "0  No matter who someone is, how they look like, ...   \n",
       "1  Biden speech draws 38.2 million USA TV viewers...   \n",
       "2  State of the union Who watched the state of th...   \n",
       "3          We Should Just Give Poor People Money nan   \n",
       "4                              Do it for the Dew nan   \n",
       "\n",
       "                                      with_stopwords  \\\n",
       "0  no matter who someone be how they look like wh...   \n",
       "1        biden speech draw million usa tv viewer nan   \n",
       "2  state of the union who watch the state of the ...   \n",
       "3          we should just give poor people money nan   \n",
       "4                              do it for the dew nan   \n",
       "\n",
       "                                   without_stopwords Political_Lean  \\\n",
       "0  matter look like language speak wear remember ...        Liberal   \n",
       "1        biden speech draw million usa tv viewer nan        Liberal   \n",
       "2        state union watch state union night opinion        Liberal   \n",
       "3                              poor people money nan        Liberal   \n",
       "4                                            dew nan        Liberal   \n",
       "\n",
       "             Subreddit                                    Dependency_Tags  \\\n",
       "0            socialism  [neg, advmod, attr, nsubj, ccomp, advmod, nsub...   \n",
       "1            democrats  [compound, nsubj, ROOT, nummod, compound, comp...   \n",
       "2  DemocraticSocialism  [ROOT, prep, det, pobj, nsubj, relcl, det, dob...   \n",
       "3      SocialDemocracy  [nsubj, aux, advmod, ROOT, amod, dative, dobj,...   \n",
       "4            democrats            [ROOT, dobj, prep, det, pobj, npadvmod]   \n",
       "\n",
       "                                            POS_Tags  \n",
       "0  [ADV, ADV, PRON, PRON, VERB, SCONJ, PRON, VERB...  \n",
       "1  [PROPN, NOUN, VERB, NUM, PROPN, PROPN, PROPN, ...  \n",
       "2  [NOUN, ADP, DET, NOUN, PRON, VERB, DET, NOUN, ...  \n",
       "3    [PRON, AUX, ADV, VERB, ADJ, NOUN, PROPN, PROPN]  \n",
       "4               [VERB, PRON, ADP, DET, PROPN, PROPN]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
