{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import *\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_data = 'https://raw.githubusercontent.com/TeodorRusKvi/Tekstanalyse/main/git_NLP_data/'\n",
    "\n",
    "# Last inn 'y_train_LSTM' fra en CSV-fil\n",
    "y_df = pd.read_csv(url_data+'y_liberal.csv')\n",
    "# Konverter hele DataFrame til et NumPy array\n",
    "y = y_df.to_numpy()\n",
    "\n",
    "# Last inn 'y_train_LSTM' fra en CSV-fil\n",
    "embeddings_GloVe = pd.read_csv(url_data+'embeddings_glove.csv')\n",
    "# Konverter hele DataFrame til et NumPy array\n",
    "embeddings_GloVe = embeddings_GloVe.to_numpy()\n",
    "\n",
    "# Last inn 'X_train_LSTM' fra en CSV-fil\n",
    "X_df = pd.read_csv(url_data+'new_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_text</th>\n",
       "      <th>with_stopwords</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>Political_Lean</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Dependency_Tags</th>\n",
       "      <th>POS_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No matter who someone is, how they look like, ...</td>\n",
       "      <td>no matter who someone be how they look like wh...</td>\n",
       "      <td>matter look like language speak wear remember ...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>socialism</td>\n",
       "      <td>['neg', 'advmod', 'attr', 'nsubj', 'ccomp', 'a...</td>\n",
       "      <td>['ADV', 'ADV', 'PRON', 'PRON', 'VERB', 'SCONJ'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden speech draws 38.2 million USA TV viewers...</td>\n",
       "      <td>biden speech draw million usa tv viewer nan</td>\n",
       "      <td>biden speech draw million usa tv viewer nan</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>['compound', 'nsubj', 'ROOT', 'nummod', 'compo...</td>\n",
       "      <td>['PROPN', 'NOUN', 'VERB', 'NUM', 'PROPN', 'PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State of the union Who watched the state of th...</td>\n",
       "      <td>state of the union who watch the state of the ...</td>\n",
       "      <td>state union watch state union night opinion</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>DemocraticSocialism</td>\n",
       "      <td>['ROOT', 'prep', 'det', 'pobj', 'nsubj', 'relc...</td>\n",
       "      <td>['NOUN', 'ADP', 'DET', 'NOUN', 'PRON', 'VERB',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Should Just Give Poor People Money nan</td>\n",
       "      <td>we should just give poor people money nan</td>\n",
       "      <td>poor people money nan</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['nsubj', 'aux', 'advmod', 'ROOT', 'amod', 'da...</td>\n",
       "      <td>['PRON', 'AUX', 'ADV', 'VERB', 'ADJ', 'NOUN', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do it for the Dew nan</td>\n",
       "      <td>do it for the dew nan</td>\n",
       "      <td>dew nan</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>['ROOT', 'dobj', 'prep', 'det', 'pobj', 'npadv...</td>\n",
       "      <td>['VERB', 'PRON', 'ADP', 'DET', 'PROPN', 'PROPN']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12849</th>\n",
       "      <td>Ron Paul’s Spirited Defense of WikiLeaks &amp; Fre...</td>\n",
       "      <td>ron paul spirited defense of wikileaks free in...</td>\n",
       "      <td>ron paul spirited defense wikileaks free infor...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>['compound', 'nsubj', 'amod', 'dobj', 'prep', ...</td>\n",
       "      <td>['PROPN', 'PROPN', 'VERB', 'NOUN', 'ADP', 'NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12850</th>\n",
       "      <td>“Anarcho-capitalism, in my opinion, is a doctr...</td>\n",
       "      <td>anarcho capitalism in my opinion be a doctrina...</td>\n",
       "      <td>anarcho capitalism opinion doctrinal system im...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>['compound', 'nsubj', 'prep', 'poss', 'pobj', ...</td>\n",
       "      <td>['PROPN', 'NOUN', 'ADP', 'PRON', 'NOUN', 'AUX'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12851</th>\n",
       "      <td>Mises Wiki is a wiki project dedicated to the ...</td>\n",
       "      <td>mises wiki be a wiki project dedicate to the a...</td>\n",
       "      <td>mises wiki wiki project dedicate advancement a...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>['ROOT', 'nsubj', 'ccomp', 'det', 'compound', ...</td>\n",
       "      <td>['VERB', 'NOUN', 'AUX', 'DET', 'NOUN', 'NOUN',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>Fireman Protection Monopoly - Is This Failed C...</td>\n",
       "      <td>fireman protection monopoly be this failed cap...</td>\n",
       "      <td>fireman protection monopoly failed capitalism nan</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>['compound', 'compound', 'nsubj', 'ROOT', 'det...</td>\n",
       "      <td>['PROPN', 'PROPN', 'NOUN', 'AUX', 'DET', 'VERB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12853</th>\n",
       "      <td>Can this Wikipedia Article be Better Written? ...</td>\n",
       "      <td>can this wikipedia article be better write i g...</td>\n",
       "      <td>wikipedia article better write listen writing ...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>['aux', 'det', 'compound', 'nsubj', 'ROOT', 'a...</td>\n",
       "      <td>['AUX', 'DET', 'NOUN', 'NOUN', 'AUX', 'ADJ', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12854 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                All_text  \\\n",
       "0      No matter who someone is, how they look like, ...   \n",
       "1      Biden speech draws 38.2 million USA TV viewers...   \n",
       "2      State of the union Who watched the state of th...   \n",
       "3              We Should Just Give Poor People Money nan   \n",
       "4                                  Do it for the Dew nan   \n",
       "...                                                  ...   \n",
       "12849  Ron Paul’s Spirited Defense of WikiLeaks & Fre...   \n",
       "12850  “Anarcho-capitalism, in my opinion, is a doctr...   \n",
       "12851  Mises Wiki is a wiki project dedicated to the ...   \n",
       "12852  Fireman Protection Monopoly - Is This Failed C...   \n",
       "12853  Can this Wikipedia Article be Better Written? ...   \n",
       "\n",
       "                                          with_stopwords  \\\n",
       "0      no matter who someone be how they look like wh...   \n",
       "1            biden speech draw million usa tv viewer nan   \n",
       "2      state of the union who watch the state of the ...   \n",
       "3              we should just give poor people money nan   \n",
       "4                                  do it for the dew nan   \n",
       "...                                                  ...   \n",
       "12849  ron paul spirited defense of wikileaks free in...   \n",
       "12850  anarcho capitalism in my opinion be a doctrina...   \n",
       "12851  mises wiki be a wiki project dedicate to the a...   \n",
       "12852  fireman protection monopoly be this failed cap...   \n",
       "12853  can this wikipedia article be better write i g...   \n",
       "\n",
       "                                       without_stopwords Political_Lean  \\\n",
       "0      matter look like language speak wear remember ...        Liberal   \n",
       "1            biden speech draw million usa tv viewer nan        Liberal   \n",
       "2            state union watch state union night opinion        Liberal   \n",
       "3                                  poor people money nan        Liberal   \n",
       "4                                                dew nan        Liberal   \n",
       "...                                                  ...            ...   \n",
       "12849  ron paul spirited defense wikileaks free infor...   Conservative   \n",
       "12850  anarcho capitalism opinion doctrinal system im...   Conservative   \n",
       "12851  mises wiki wiki project dedicate advancement a...   Conservative   \n",
       "12852  fireman protection monopoly failed capitalism nan   Conservative   \n",
       "12853  wikipedia article better write listen writing ...   Conservative   \n",
       "\n",
       "                 Subreddit                                    Dependency_Tags  \\\n",
       "0                socialism  ['neg', 'advmod', 'attr', 'nsubj', 'ccomp', 'a...   \n",
       "1                democrats  ['compound', 'nsubj', 'ROOT', 'nummod', 'compo...   \n",
       "2      DemocraticSocialism  ['ROOT', 'prep', 'det', 'pobj', 'nsubj', 'relc...   \n",
       "3          SocialDemocracy  ['nsubj', 'aux', 'advmod', 'ROOT', 'amod', 'da...   \n",
       "4                democrats  ['ROOT', 'dobj', 'prep', 'det', 'pobj', 'npadv...   \n",
       "...                    ...                                                ...   \n",
       "12849    anarchocapitalism  ['compound', 'nsubj', 'amod', 'dobj', 'prep', ...   \n",
       "12850    anarchocapitalism  ['compound', 'nsubj', 'prep', 'poss', 'pobj', ...   \n",
       "12851    anarchocapitalism  ['ROOT', 'nsubj', 'ccomp', 'det', 'compound', ...   \n",
       "12852    anarchocapitalism  ['compound', 'compound', 'nsubj', 'ROOT', 'det...   \n",
       "12853    anarchocapitalism  ['aux', 'det', 'compound', 'nsubj', 'ROOT', 'a...   \n",
       "\n",
       "                                                POS_Tags  \n",
       "0      ['ADV', 'ADV', 'PRON', 'PRON', 'VERB', 'SCONJ'...  \n",
       "1      ['PROPN', 'NOUN', 'VERB', 'NUM', 'PROPN', 'PRO...  \n",
       "2      ['NOUN', 'ADP', 'DET', 'NOUN', 'PRON', 'VERB',...  \n",
       "3      ['PRON', 'AUX', 'ADV', 'VERB', 'ADJ', 'NOUN', ...  \n",
       "4       ['VERB', 'PRON', 'ADP', 'DET', 'PROPN', 'PROPN']  \n",
       "...                                                  ...  \n",
       "12849  ['PROPN', 'PROPN', 'VERB', 'NOUN', 'ADP', 'NOU...  \n",
       "12850  ['PROPN', 'NOUN', 'ADP', 'PRON', 'NOUN', 'AUX'...  \n",
       "12851  ['VERB', 'NOUN', 'AUX', 'DET', 'NOUN', 'NOUN',...  \n",
       "12852  ['PROPN', 'PROPN', 'NOUN', 'AUX', 'DET', 'VERB...  \n",
       "12853  ['AUX', 'DET', 'NOUN', 'NOUN', 'AUX', 'ADJ', '...  \n",
       "\n",
       "[12854 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1= X_df['without_stopwords']\n",
    "\n",
    "# Konverter kolonnen til et NumPy array\n",
    "X = X_1.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df.rename(columns={'with_stopwords': 'without_stopwords', 'without_stopwords': 'with_stopwords'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "trunc_type = \"post\"\n",
    "padding_type = \"post\"\n",
    "vocab_size = embeddings_GloVe.shape[0]\n",
    "# This is fixed.\n",
    "embedding_dim = 100\n",
    "EPOCHS=20\n",
    "BATCH_SIZE = 32\n",
    "num_classes = 1\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from kan import KAN, create_datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Set device to CPU\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m KAN(width\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m], grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\bugat\\anaconda3\\Lib\\site-packages\\kan\\KAN.py:140\u001b[0m, in \u001b[0;36mKAN.__init__\u001b[1;34m(self, width, grid, k, noise_scale, noise_scale_base, base_fun, symbolic_enabled, bias_trainable, grid_eps, grid_range, sp_trainable, sb_trainable, device, seed)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# splines\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     scale_base \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(width[l]) \u001b[38;5;241m+\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrandn(width[l] \u001b[38;5;241m*\u001b[39m width[l \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m noise_scale_base\n\u001b[1;32m--> 140\u001b[0m     sp_batch \u001b[38;5;241m=\u001b[39m KANLayer(in_dim\u001b[38;5;241m=\u001b[39mwidth[l], out_dim\u001b[38;5;241m=\u001b[39mwidth[l \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], num\u001b[38;5;241m=\u001b[39mgrid, k\u001b[38;5;241m=\u001b[39mk, noise_scale\u001b[38;5;241m=\u001b[39mnoise_scale, scale_base\u001b[38;5;241m=\u001b[39mscale_base, scale_sp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m, base_fun\u001b[38;5;241m=\u001b[39mbase_fun, grid_eps\u001b[38;5;241m=\u001b[39mgrid_eps, grid_range\u001b[38;5;241m=\u001b[39mgrid_range, sp_trainable\u001b[38;5;241m=\u001b[39msp_trainable,\n\u001b[0;32m    141\u001b[0m                         sb_trainable\u001b[38;5;241m=\u001b[39msb_trainable, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fun\u001b[38;5;241m.\u001b[39mappend(sp_batch)\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# bias\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bugat\\anaconda3\\Lib\\site-packages\\kan\\KANLayer.py:126\u001b[0m, in \u001b[0;36mKANLayer.__init__\u001b[1;34m(self, in_dim, out_dim, num, k, noise_scale, scale_base, scale_sp, base_fun, grid_eps, grid_range, sp_trainable, sb_trainable, device)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_base \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mones(size, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m scale_base)\u001b[38;5;241m.\u001b[39mrequires_grad_(sb_trainable)  \u001b[38;5;66;03m# make scale trainable\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_base \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mFloatTensor(scale_base)\u001b[38;5;241m.\u001b[39mcuda())\u001b[38;5;241m.\u001b[39mrequires_grad_(sb_trainable)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_sp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mones(size, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m scale_sp)\u001b[38;5;241m.\u001b[39mrequires_grad_(sp_trainable)  \u001b[38;5;66;03m# make scale trainable\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun \u001b[38;5;241m=\u001b[39m base_fun\n",
      "File \u001b[1;32mc:\\Users\\bugat\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cpu')  # Set device to CPU\n",
    "model = KAN(width=[2,5,1], grid=5, k=3, seed=0, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m KAN(width\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m], grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\bugat\\anaconda3\\Lib\\site-packages\\kan\\KAN.py:140\u001b[0m, in \u001b[0;36mKAN.__init__\u001b[1;34m(self, width, grid, k, noise_scale, noise_scale_base, base_fun, symbolic_enabled, bias_trainable, grid_eps, grid_range, sp_trainable, sb_trainable, device, seed)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# splines\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     scale_base \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(width[l]) \u001b[38;5;241m+\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrandn(width[l] \u001b[38;5;241m*\u001b[39m width[l \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m noise_scale_base\n\u001b[1;32m--> 140\u001b[0m     sp_batch \u001b[38;5;241m=\u001b[39m KANLayer(in_dim\u001b[38;5;241m=\u001b[39mwidth[l], out_dim\u001b[38;5;241m=\u001b[39mwidth[l \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], num\u001b[38;5;241m=\u001b[39mgrid, k\u001b[38;5;241m=\u001b[39mk, noise_scale\u001b[38;5;241m=\u001b[39mnoise_scale, scale_base\u001b[38;5;241m=\u001b[39mscale_base, scale_sp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m, base_fun\u001b[38;5;241m=\u001b[39mbase_fun, grid_eps\u001b[38;5;241m=\u001b[39mgrid_eps, grid_range\u001b[38;5;241m=\u001b[39mgrid_range, sp_trainable\u001b[38;5;241m=\u001b[39msp_trainable,\n\u001b[0;32m    141\u001b[0m                         sb_trainable\u001b[38;5;241m=\u001b[39msb_trainable, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fun\u001b[38;5;241m.\u001b[39mappend(sp_batch)\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# bias\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bugat\\anaconda3\\Lib\\site-packages\\kan\\KANLayer.py:126\u001b[0m, in \u001b[0;36mKANLayer.__init__\u001b[1;34m(self, in_dim, out_dim, num, k, noise_scale, scale_base, scale_sp, base_fun, grid_eps, grid_range, sp_trainable, sb_trainable, device)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_base \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mones(size, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m scale_base)\u001b[38;5;241m.\u001b[39mrequires_grad_(sb_trainable)  \u001b[38;5;66;03m# make scale trainable\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_base \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mFloatTensor(scale_base)\u001b[38;5;241m.\u001b[39mcuda())\u001b[38;5;241m.\u001b[39mrequires_grad_(sb_trainable)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_sp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mones(size, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m scale_sp)\u001b[38;5;241m.\u001b[39mrequires_grad_(sp_trainable)  \u001b[38;5;66;03m# make scale trainable\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun \u001b[38;5;241m=\u001b[39m base_fun\n",
      "File \u001b[1;32mc:\\Users\\bugat\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model = KAN(width=[2,5,1], grid=5, k=3, seed=0, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
